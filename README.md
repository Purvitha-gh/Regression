📌 Project Overview
-Generates sample 1D data using a sine function plus Gaussian noise.
-Applies multiple regression algorithms from scikit-learn.
-Visualizes predictions of each model on the same dataset.

📊 Implemented Regression Models
1) Linear Regression
2)Polynomial Regression (degree 3)
3)Ridge Regression
4)Lasso Regression
5)ElasticNet Regression
6)Support Vector Regression (SVR) with RBF kernel
7)Decision Tree Regression
8)Random Forest Regression

🛠️ Requirements
Install required packages using pip:
pip install numpy matplotlib scikit-learn
🚀 How to Run
-Open the notebook regression.ipynb in Jupyter Notebook or any compatible environment.
-Run each cell sequentially.
-Each model will display its prediction curve on the dataset.

📈 Visualization
-Each model includes a plot showing:
-Original data points (in red or blue)
-Predicted regression curve (in yellow or red)
-These visuals help compare the model's ability to fit noisy, non-linear data.

🧠 Key Concepts
-Overfitting vs. underfitting in polynomial models.
-Regularization using Ridge, Lasso, and ElasticNet.
-Model complexity in tree-based regressors.
-Normalization for SVR.
